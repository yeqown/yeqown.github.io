<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Yeqown</title>
    <link>https://www.yeqown.xyz/tags/Kubernetes/</link>
    <description>Recent content in Kubernetes on Yeqown</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 08 May 2025 09:35:14 +0800</lastBuildDate>
    <atom:link href="https://www.yeqown.xyz/tags/Kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在 Kubernetes 中实现 gRPC 流量的镜像和对比</title>
      <link>https://www.yeqown.xyz/2025/05/08/%E5%9C%A8-Kubernetes%E4%B8%AD%E5%AE%9E%E7%8E%B0gRPC%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/</link>
      <pubDate>Thu, 08 May 2025 09:35:14 +0800</pubDate>
      <guid>https://www.yeqown.xyz/2025/05/08/%E5%9C%A8-Kubernetes%E4%B8%AD%E5%AE%9E%E7%8E%B0gRPC%E6%B5%81%E9%87%8F%E9%95%9C%E5%83%8F/</guid>
      <description>&lt;p&gt;本文主要解决在服务重构过程中如何保证新旧服务行为一致性的问题。&lt;/p&gt;&#xA;&lt;h2 id=&#34;场景描述&#34;&gt;&#xA;  场景描述&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%9c%ba%e6%99%af%e6%8f%8f%e8%bf%b0&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;现有一个 python 开发的 gRPC 微服务提供了一些 &lt;strong&gt;数据查询&lt;/strong&gt; 接口 供 上层应用使用，随着业务流量的增加运维这个服务的成本也逐渐增加，为了降低运维成本和提高性能 (木有擅长 python 高性能的开发)，因此选择了使用 go 语言对这个服务进行重写。在开发完成之后，需要对新服务的 gRPC 接口进行验证。&lt;/p&gt;&#xA;&lt;p&gt;这种场景对测试开发人员来说，实在是太熟悉了吧？典型的 &lt;strong&gt;重放验证&lt;/strong&gt;，马上能想到的验证手段就是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果有存量的单元测试，那么直接重新跑一遍单元测试就能快速的完成验证。&lt;/li&gt;&#xA;&lt;li&gt;没有单元测试的情况，那么可以将新服务部署起来，通过流量复制的方式将旧服务的流量复制到新服务上，然后对比两个服务的返回结果是否一致。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&#xA;&lt;script src=&#34;https://www.yeqown.xyz/mermaid.min.js&#34;&gt;&lt;/script&gt;&#xA;&#xA;  &lt;script&gt;mermaid.initialize({&#xA;  &#34;flowchart&#34;: {&#xA;    &#34;useMaxWidth&#34;:true&#xA;  },&#xA;  &#34;theme&#34;: &#34;default&#34;&#xA;}&#xA;)&lt;/script&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;mermaid&#34;&gt;&#xA;flowchart LR&#xA;    %% 定义布局方向和间距&#xA;    subgraph s1[&#34;方案一: 单元测试验证&#34;]&#xA;        direction TB&#xA;        UT[单元测试] --&gt;|执行| NS1[新服务]&#xA;    end&#xA;    &#xA;    subgraph s2[&#34;方案二: 流量复制验证&#34;]&#xA;        direction TB&#xA;        C[客户端] --&gt;|请求| OS[旧服务]&#xA;        OS --&gt;|响应| C&#xA;        OS --&gt;|复制流量| NS2[新服务]&#xA;        NS2 --&gt;|对比响应| OS&#xA;    end&#xA;&#xA;    %% 设置布局方向和对齐方式&#xA;    s1 ~~~ s2&#xA;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;但是很遗憾 😭，并没有成熟的单元测试；测试人员也都是人肉测试，对于内部服务的接口验证帮助不大，因此这里采用第二种方式进行验证。&lt;/p&gt;</description>
    </item>
    <item>
      <title>在 K8S 中部署存算分离 Doris 集群</title>
      <link>https://www.yeqown.xyz/2025/02/28/%E5%9C%A8k8s%E4%B8%AD%E6%90%AD%E5%BB%BA%E5%AD%98%E7%AE%97%E5%88%86%E7%A6%BB%E7%9A%84Doris%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Fri, 28 Feb 2025 16:50:41 +0800</pubDate>
      <guid>https://www.yeqown.xyz/2025/02/28/%E5%9C%A8k8s%E4%B8%AD%E6%90%AD%E5%BB%BA%E5%AD%98%E7%AE%97%E5%88%86%E7%A6%BB%E7%9A%84Doris%E9%9B%86%E7%BE%A4/</guid>
      <description>&lt;blockquote class=&#34;book-hint info&#34;&gt;&#xA;&lt;p&gt;本文记录了在 ubuntu 22.04 上配合 minikube 搭建的 k8s 集群，搭建 doris 存算分离集群的过程。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;0-环境信息&#34;&gt;&#xA;  0. 环境信息&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#0-%e7%8e%af%e5%a2%83%e4%bf%a1%e6%81%af&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;软件&lt;/th&gt;&#xA;          &lt;th&gt;版本&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;OS&lt;/td&gt;&#xA;          &lt;td&gt;Ubuntu 24.04.1 LTS x86_64&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;kernel&lt;/td&gt;&#xA;          &lt;td&gt;6.8.0-52-generic&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;minikube&lt;/td&gt;&#xA;          &lt;td&gt;v1.35.0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;kubernetes&lt;/td&gt;&#xA;          &lt;td&gt;v1.32.0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;doris&lt;/td&gt;&#xA;          &lt;td&gt;v3.0.3&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;这里默认已经准备好了基础的 kubernetes 集群，所以也不再阐述如何通过 minikube 或者其他方式搭建 kubernetes 集群。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-安装-foundationdb&#34;&gt;&#xA;  1. 安装 FoundationDB&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#1-%e5%ae%89%e8%a3%85-foundationdb&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;参考文档：https://doris.apache.org/zh-CN/docs/3.0/install/deploy-on-kubernetes/separating-storage-compute/install-fdb&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h4 id=&#34;11-安装-foundationdb-crd-资源&#34;&gt;&#xA;  1.1 安装 FoundationDB CRD 资源&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#11-%e5%ae%89%e8%a3%85-foundationdb-crd-%e8%b5%84%e6%ba%90&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/FoundationDB/fdb-kubernetes-operator/main/config/crd/bases/apps.foundationdb.org_foundationdbclusters.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/FoundationDB/fdb-kubernetes-operator/main/config/crd/bases/apps.foundationdb.org_foundationdbbackups.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/FoundationDB/fdb-kubernetes-operator/main/config/crd/bases/apps.foundationdb.org_foundationdbrestores.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;12-部署-foundationdb-operator&#34;&gt;&#xA;  1.2 部署 FoundationDB Operator&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#12-%e9%83%a8%e7%bd%b2-foundationdb-operator&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://raw.githubusercontent.com/apache/doris-operator/master/config/operator/fdb-operator.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f fdb-operator.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;13-部署-foundationdb-集群&#34;&gt;&#xA;  1.3 部署 FoundationDB 集群&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#13-%e9%83%a8%e7%bd%b2-foundationdb-%e9%9b%86%e7%be%a4&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://raw.githubusercontent.com/foundationdb/fdb-kubernetes-operator/main/config/samples/cluster.yaml -O fdb-cluster.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f fdb-cluster.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 查看集群状态&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get fdb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 预期输出（启动需要时间，需要等待几分钟）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           GENERATION   RECONCILED   AVAILABLE   FULLREPLICATION   VERSION   AGE&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test-cluster   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;            true        true              7.1.26    3m30s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-安装-doris-operator&#34;&gt;&#xA;  2. 安装 Doris Operator&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-%e5%ae%89%e8%a3%85-doris-operator&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;21-安装-crd-部署-doris-相关资源定义&#34;&gt;&#xA;  2.1 安装 CRD 部署 Doris 相关资源定义&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#21-%e5%ae%89%e8%a3%85-crd-%e9%83%a8%e7%bd%b2-doris-%e7%9b%b8%e5%85%b3%e8%b5%84%e6%ba%90%e5%ae%9a%e4%b9%89&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create -f https://raw.githubusercontent.com/apache/doris-operator/master/config/crd/bases/crds.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;22-部署-doris-operator&#34;&gt;&#xA;  2.2 部署 Doris Operator&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#22-%e9%83%a8%e7%bd%b2-doris-operator&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://raw.githubusercontent.com/apache/doris-operator/master/config/operator/disaggregated-operator.yaml -O disaggregated-operator.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f disaggregated-operator.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 查看部署状态&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get pod -n doris&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 预期输出&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                              READY   STATUS    RESTARTS   AGE&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;doris-operator-5fd65d8d69-rgqlk   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          79s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-部署存算分离集群&#34;&gt;&#xA;  3. 部署存算分离集群&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#3-%e9%83%a8%e7%bd%b2%e5%ad%98%e7%ae%97%e5%88%86%e7%a6%bb%e9%9b%86%e7%be%a4&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;31-下载示例配置&#34;&gt;&#xA;  3.1 下载示例配置&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#31-%e4%b8%8b%e8%bd%bd%e7%a4%ba%e4%be%8b%e9%85%8d%e7%bd%ae&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://raw.githubusercontent.com/apache/doris-operator/master/doc/examples/disaggregated/cluster/ddc-sample.yaml -O ddc-sample.yaml&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;32-配置-configmap&#34;&gt;&#xA;  3.2 配置 ConfigMap&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#32-%e9%85%8d%e7%bd%ae-configmap&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;对于 ddc-sample.yaml 配置进行调整配置。这三个都需要分别配置 ConfigMap 并修改集群中的配置挂载。&lt;/p&gt;</description>
    </item>
    <item>
      <title>在istio服务网格中扩展自定义功能</title>
      <link>https://www.yeqown.xyz/2023/11/17/%E5%9C%A8istio%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E4%B8%AD%E6%89%A9%E5%B1%95%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Fri, 17 Nov 2023 22:48:59 +0800</pubDate>
      <guid>https://www.yeqown.xyz/2023/11/17/%E5%9C%A8istio%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E4%B8%AD%E6%89%A9%E5%B1%95%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8A%9F%E8%83%BD/</guid>
      <description>&lt;h3 id=&#34;前提&#34;&gt;&#xA;  前提&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%89%8d%e6%8f%90&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;本文假设你已经对 Kubernetes、istio 和 Envoy 有一定的了解，如果你还不了解，可以先阅读下面的文章：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Kubernetes: &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&#34;&gt;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;istio: &lt;a href=&#34;https://istio.io/latest/docs/concepts/what-is-istio/&#34;&gt;https://istio.io/latest/docs/concepts/what-is-istio/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Envoy: &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/what_is_envoy&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/what_is_envoy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当然不仅限于知道这些，还需要对其有一定的实践经验，这样才能更好的理解本文的内容。当然本文也不会涉及太深，只是作为 istio 的一个入门扩展教程。&lt;/p&gt;&#xA;&lt;h3 id=&#34;为什么要扩展功能背景&#34;&gt;&#xA;  为什么要扩展功能？#背景&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e6%89%a9%e5%b1%95%e5%8a%9f%e8%83%bd%e8%83%8c%e6%99%af&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;用通俗的话去理解 istio 的作用就是，对我们部署在 kubernetes 上的应用进行流量控制（代理），给我们提供了：流量控制、流量监控、流量安全等功能。但是在实际的使用中，我们还是会遇到一些特殊的场景，需要我们自己基于自己的业务场景去扩展一些功能，比如：ip 白名单、ip 黑名单、统一认证等。这些功能往往和具体公司的业务场景有关，因此 istio 无法直接提供这些功能，需要我们自己去扩展。&lt;/p&gt;&#xA;&lt;h4 id=&#34;传统的扩展方式&#34;&gt;&#xA;  传统的扩展方式&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e4%bc%a0%e7%bb%9f%e7%9a%84%e6%89%a9%e5%b1%95%e6%96%b9%e5%bc%8f&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;在传统架构中，常常通过 API 网关这一组件来实现这一些扩展能力，常用的 API 网关有：kong、apisix、openresty，而扩展的原理就是插件，或者像 nginx/openresty 在请求链中的不同阶段提供了不同的 hook，我们可以基于这些 hook 来实现扩展功能。&lt;/p&gt;&#xA;&lt;p&gt;就我个人的经历来说，网关要么自己定制开发，要么基于openresty来实现，又或者使用一些开源的网关，如：kong、apisix，在此基础上进行二次开发。不过这些方式都是在传统API网关中去实现的，随着 Service Mesh 的发展，API网关的某些功能也被 Sidecar 代理所取代，比如：流量控制、流量监控、流量安全等。目前 Mesh 发展的趋势也是进一步在 Sidecar 代理中实现更多的功能，而不是在 API 网关中实现。&lt;/p&gt;&#xA;&lt;h3 id=&#34;envoy-的扩展能力&#34;&gt;&#xA;  Envoy 的扩展能力&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#envoy-%e7%9a%84%e6%89%a9%e5%b1%95%e8%83%bd%e5%8a%9b&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/extending/extending&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/extending/extending&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=XdWmm_mtVXI&#34;&gt;https://www.youtube.com/watch?v=XdWmm_mtVXI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;envoy 提供了丰富的扩展能力，Access Logger, Access Log Filter, Clusters, Listen Filter, Network Filter, HTTP Filter 等等。这一块内容非常多，如果想要了解更多，请参考官方文档。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kubernetes中gRPC Load Balancing分析和解决</title>
      <link>https://www.yeqown.xyz/2020/09/22/Kubernetes%E4%B8%ADgRPC-Load-Balancing%E5%88%86%E6%9E%90%E5%92%8C%E8%A7%A3%E5%86%B3/</link>
      <pubDate>Tue, 22 Sep 2020 13:33:20 +0800</pubDate>
      <guid>https://www.yeqown.xyz/2020/09/22/Kubernetes%E4%B8%ADgRPC-Load-Balancing%E5%88%86%E6%9E%90%E5%92%8C%E8%A7%A3%E5%86%B3/</guid>
      <description>&lt;h3 id=&#34;背景&#34;&gt;&#xA;  背景&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%83%8c%e6%99%af&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;第一次，线上遇到大量接口RT超过10s触发了系统告警，运维反馈k8s集群无异常，负载无明显上升。将报警接口相关的服务重启一番后发现并无改善。但是开发人员使用链路追踪系统发现，比较慢的请求总是某个gRPC服务中的几个POD导致，由其他POD处理的请求并不会出现超时告警。&lt;/p&gt;&#xA;&lt;p&gt;第二次，同样遇到接口RT超过阈值触发告警，从k8s中查到某个gRPC服务（关键服务）重启次数异常，查看重启原因时发现是&lt;code&gt;OOM Killed&lt;/code&gt;，&lt;code&gt;OOM killed&lt;/code&gt;并不是负载不均衡直接导致的，但是也有一定的关系，这个后面再说。前两次由于监控不够完善（于我而言，运维的很多面板都没有权限，没办法排查）。期间利用pprof分析了该服务内存泄漏点，并修复上线观察。经过第二次问题并解决之后，线上超时告警恢复正常水平，但是该 deployment 下的几个POD占用资源（Mem / CPU / Network-IO），差距甚大。&lt;/p&gt;&#xA;&lt;img src=&#34;https://www.yeqown.xyz/images/k8s-grpc-lb-mem1.jpg&#34;/&gt;&#xA;&lt;img src=&#34;https://www.yeqown.xyz/images/k8s-grpc-lb-mem2.jpg&#34;/&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;第二张图是运维第一次发现该服务OOM killed 之后调整了内存上限从 512MB =&amp;gt; 1G，然而只是让它死得慢一点而已。&#xA;从上面两张图能够石锤的是该服务一定存在内存泄漏。Go项目内存占用的分析，我总结了如下的排查步骤：&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1. 代码泄漏（pprof）（可能原因 goroutine泄漏；闭包）&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2. Go Runtime + Linux 内核（RSS虚高导致OOM）https://github.com/golang/go/issues/23687&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;3. 采集指标不正常（container_memory_working_set_bytes）&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2，3 是基于第1点能基本排除代码问题的后续步骤。&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;解决和排查手段：&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1. pprof 通过heap + goroutine 是否异常，来定位泄漏点&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;运行&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;go tool pprof&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;命令时加上--nodefration&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0.05参数，表示如果调用的子函数使用的CPU、memory不超过 5%，就忽略它。&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2. 确认go版本和内核版本，确认是否开启了MADV_FREE，导致RSS下降不及时&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1.12+ 和 linux内核版本大于 4.5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;。&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;3.  RSS + Cache 内存检查&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; Cache 过大的原因 https://www.cnblogs.com/zh94/p/11922714.html &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;// IO密集：手动释放或者定期重启&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;查看服务器内存使用情况： &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;free -g&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;查看进程内存情况：      &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pidstat -rI -p 13744&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;查看进程打开的文件：    &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;lsof -p 13744&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;查看容器内的PID：      &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;docker inspect --format &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ .State.Pid}}&amp;#34;&lt;/span&gt; 6e7efbb80a9d&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;查看进程树，找到目标:   &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pstree -p 13744&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;参考：https://eddycjy.com/posts/why-container-memory-exceed/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过上述步骤，我发现了该POD被&lt;code&gt;OOM killed&lt;/code&gt;还有另一个元凶就是，&lt;strong&gt;日志文件占用&lt;/strong&gt;。这里就不过多的详述了，搜索方向是 “一个运行中程序在内存中如何组织 + Cache内存是由哪些部分构成的”。这部分要达到的目标是：一个程序运行起来它为什么占用了这么些内存，而不是更多或者更少。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
